数据馆员的Spark简明手册 PDF下载 顾立平，马景源编著 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#751893015
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#751893015
<p>书名:数据馆员的Spark简明手册</p><p>作者:顾立平，马景源编著</p><p>页数:83页</p><p>定价:¥28.0</p><p>出版社:科学技术文献出版社</p><p>出版日期:2017-10-01</p><p>ISBN:9787518930159</p><p><h2>节选</h2></p>[<p>　　《数据馆员的Spark简明手册》：　　Spark给出了不同的属性来指定不同的缓存方式：是否使用磁盘、是否使用内存、是否进行反序列化（即不进行序列化）、备份数目，依照不同的属性对缓存方式进行了定义。另外，有以下两点需要注意。　　①Spark默认存储策略为MEMORY_ONLY：只缓存到内存并且以原生方式保存（反序列化）一个副本。　　②MEMORY AND_DISK存储级别在内存够用时直接保存到内存中，只有当内存不足时，才会存储到磁盘中。　　4.8 宽依赖和窄依赖　　RDD之间的依赖关系分为宽依赖和窄依赖两类（图4-2）。对于窄依赖，子RDD的每个分区依赖于常数个父分区，它与数据规模无关。输入输出是一对一的算子，但是其中一种方式的结果RDD的分区结构不变，主要是Map、flatMap。但是如union、coalesce结果RDD的分区结构会发生变化。对于宽依赖，子RDD的每个分区都依赖于所有的父RDD分区。　　对于两种依赖关系，窄依赖允许在一个集群节点上以流水线的方式计算所有父分区；而宽依赖则需要首先计算好所有父分区数据，然后在节点之间进行Shuffle。　　……</p>]<p><h2>内容简介</h2></p>[<p>本书旨在协助初级数据馆员们能够迅速了解SPARK方面的知识、用途以及整体概貌, 作为进一步实践操作层面之前的入门基础读物。Spark是由伯克利大学 (Berkeley) 开源的计算框架, 其特点是能够将任务的中间结果保存在内存中, 不进行读写磁盘的操作, 因而能够实现更快地处理。它在解决复杂线性代数、某些优化问题、迭代计算、机器学习等方面具有较强优势。</p>]<p><h2>作者简介</h2></p>[<p>　　顾立平（Alan Ku），博士、教授。在中国科学院文献情报中心从事开放获取、著作权、数据权益的政策研究与建议；在中国科学院大学经济与管理学院讲授信息用户与服务研究。学术理念和工作信念是：好做事（态度）、做好事（方向）、做事好（目标）。</p>]<p><h2>目录</h2></p>
    第1章 Spark生态介绍1．1 MapReduce、Storm和Spark模型比较1．2 Spark产生背景1．3 Spark的内存计算框架1．4 Spark Strearning：流式计算框架1．5 Spark SQL1．6 Spark MLlib：机器学习1．7 Spark GraphX和取代Bagel的理由1．8 BlinkDB1．9 SparkR第2章 Spark的安装与运行2．1 Spark的安装2．1．1 Spark的源码编译方式2．1．2 Spark Standalone安装2．1．3 Spark应用程序部署工具spark-submit2．1．4 Spark的高可用性部署2．2 Spark的运行架构2．2．1 基本术语2．2．2 运行架构2．2．3 Spark on Standalone的运行过程2．2．4 Spark on YARN的运行过程2．3 Spark的运行2．3．1 Spark on Standalone2．3．2 Spark on YARN2．3．3 Standalone与YARN模式优缺点比较第3章 Spark的scala编程3．1 Scala开发环境搭建3．2 Scala开发Spark应用程序3．3 编程实现3．3．1 使用Java编程3．3．2 使用Python编程第4章 spark的编程模型和解析4．1 SpaEk的编程模型4．2 RDD的特点、操作、依赖关系4．3 Spark应用程序的配置4．4 Spark的架构4．5 Spark的容错机制4．6 数据的本地性4．7 缓存策略介绍4．8 宽依赖和窄依赖第5章 Spark数据挖掘5．1 MLlib5．2 GraphX5．2．1 GraphX原理5．2．2 Table Operator和Graph Operator的区别5．2．3 Vertices、Edges和Triplets介绍5．2．4 GraphX图构造者5．3 SparkR5．3．1 SparkR原理5．3．2 如何运行SparkR第6章 Spark Strearning6．1 Spark Strearning与Storm的区别6．2 Kafka的部署6．3 Kafka与Spark Strearning的整合6．4 Spark Strearning原理6．4．1 Spark流式处理架构6．4．2 DStream的特点6．4．3 Dstream的操作和RDD的区别6．4．4 无状态转换操作与有状态转换操作6．4．5 优化Spark Strearning6．5 Strearning的容错机制6．6 Strearning在YARN模式下的注意事项第7章 Spark优化7．1 序列化优化——Knro7．2 Spark参数优化7．3 Spark任务的均匀分布策略7．4 Partition key倾斜的解决方案7．5 Spark任务的监控7．6 GC的优化7．7 Spark Streaming吞吐量优化7．8 Spark RDD使用内存的优化策略第8章 SQL on Spark8．1 BDAS数据分析软件栈8．2 Spark SQL工具8．3 Spark SQL原理8．4 Spark SQL编程
