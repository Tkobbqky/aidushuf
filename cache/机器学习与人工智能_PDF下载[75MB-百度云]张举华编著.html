机器学习与人工智能 PDF下载 张举华编著 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#703064956
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#703064956
<p>书名:机器学习与人工智能</p><p>作者:张举华编著</p><p>页数:12,213页</p><p>定价:¥59.0</p><p>出版社:科学出版社</p><p>出版日期:2020-06-01</p><p>ISBN:9787030649560</p><p><h2>本书特色</h2></p>[<p>
《机器学习与人工智能》涵盖了与人工智能相关的机器学习核心方法，包括深度卷积神经网络、循环神经网络、生成对抗网络、蒙特卡罗树搜索、强化学习。《机器学习与人工智能》也包括一些应用非常广泛的机器学习方法，例如，支持向量机、决策树和随机森林、隐马尔可夫模型、聚类与自组织映射。《机器学习与人工智能》还包含一些重要的大数据分析方法，如主成分分析、回归分析等。
                                        </p>]<p><h2>内容简介</h2></p>[<p>本书涵盖了与人工智能相关的机器学习核心方法, 包括深度卷积神经网络、循环神经网络、生成式对抗网络、蒙特卡罗树搜索、强化学习。本书也包括一些应用非常广泛的机器学习方法, 例如, 支持向量机、决策树和随机森林、隐马尔可夫模型、聚类与自组织映射。本书还包含一些重要的大数据分析方法, 如主成分分析、回归分析等。</p>]<p><h2>目录</h2></p>
    目录 第1章 导言 1 1.1 机器学习的概念 1 1.2 机器学习的类别 1 1.3 机器学习和其他领域的关系 2 1.4 人工智能的发展历程 3 1.5 机器学习和人工智能的关系 5 第2章 机器学习基础 7 2.1 概率和统计基础 7 2.1.1 概率 7 2.1.2 随机变量 8 2.1.3 线性相关 9 2.1.4 常用概率分布 10 2.1.5 贝叶斯定理 11 2.2 凸函数 12 2.3 极大似然估计 13 2.4 熵和散度 13 2.5 主成分分析 15 2.5.1 数据标准化 15 2.5.2 数据矩阵的正交变换 16 2.5.3 主成分 18 2.5.4 因子和因子载荷 18 2.6 随机梯度下降算法 19 2.6.1 函数的梯度和方向导数 19 2.6.2 梯度下降算法 20 2.6.3 随机梯度下降 20 2.6.4 动量 21 2.7 过拟合和欠拟合 22 2.8 交叉验证 22 2.9 二分类模型的评价 23 2.10 机器学习的工具包 26 第3章 回归分析 27 3.1 回归分析问题 27 3.2 线性回归分析 283.2.1 线性回归分析问题 28 3.2.2 线性回归形式 29 3.2.3 简单线性回归 29 3.3 Logistic回归 30 3.3.1 Logistic函数 30 3.3.2 线性二分类 31 3.3.3 对数似然函数与代价函数 32 3.3.4 **参数的学习 34 第4章 支持向量机 36 4.1 引言 36 4.2 二分类支持向量机算法 36 4.2.1 二分类线性支持向量机 37 4.2.2 二分类非线性支持向量机 41 4.2.3 核函数 42 4.3 支持向量机分类性能的评价 43 4.4 序贯*小优化算法 44 第5章 聚类和自组织映射 47 5.1 向量、范数和向量间的距离 47 5.2 K-均值聚类 48 5.3 自组织映射 49 5.3.1 Kohonen模型 49 5.3.2 突触权重向量的初始化 50 5.3.3 竞争过程 50 5.3.4 合作过程 50 5.3.5 自适应过程 52 5.3.6 定序与收敛 53 第6章 隐马尔可夫模型 55 6.1 马尔可夫链 55 6.2 隐马尔可夫模型的含义 56 6.2.1 模型的含义 56 6.2.2 统计推断 58 6.3 后验概率解码 58 6.4 状态路径的推断 60 6.5 隐马尔可夫模型中参数的估计 61 6.5.1 已知完整数据的参数估计 62 6.5.2 期望**算法 62 6.5.3 Baum-Welch算法 65第7章 决策树和随机森林 67 7.1 树 67 7.1.1 图 67 7.1.2 二叉树 68 7.2 决策树学习 69 7.2.1 度量 69 7.2.2 ID3算法 71 7.2.3 C4.5算法 74 7.3 自举聚集法 75 7.4 随机森林 76 第8章 蒙特卡罗树搜索 77 8.1 引言 77 8.2 蒙特卡罗积分 78 8.3 博弈 78 8.3.1 组合博弈 79 8.3.2 博弈树 79 8.3.3 极小极大算法 79 8.3.4 多臂老虎机 81 8.3.5 2-贪心 82 8.3.6 遗憾 82 8.3.7 上置信界 82 8.4 蒙特卡罗树搜索算法 83 8.5 树的上置信界 85 8.6 蒙特卡罗树搜索的特征 87 8.6.1 启发式 87 8.6.2 随时性 88 8.6.3 非对称性 88 第9章 卷积神经网络 89 9.1 引言 89 9.2 有监督学习 90 9.3 背景知识 91 9.3.1 张量和向量化 91 9.3.2 向量的计算以及链式法则 91 9.3.3 克罗内克积 92 9.4 CNN简述 92 9.4.1 结构 92 9.4.2 前向传播 93 9.4.3 随机梯度下降 939.4.4 误差反向传播 93 9.5 卷积层 94 9.5.1 输入，输出，滤波，记号 94 9.5.2 卷积 95 9.5.3 卷积展开 95 9.5.4 卷积展开的推广 96 9.5.5 更高维度的指标矩阵 98 9.5.6 反向传播的参数 99 9.5.7 反向传播：监督信号 100 9.6 池化层 101 9.7 逆向操作 102 9.8 ReLU层 103 第10章 深度卷积神经网络 104 10.1 Alex网络 104 10.2 VGG网络 106 10.3 Inception网络 107 10.4 残差网络 111 10.4.1 残差块 112 10.4.2 残差网络的结构 113 10.5 深度卷积神经网络的训练 114 10.5.1 权值初始化 114 10.5.2 学习率更新 115 10.5.3 批量正则化 115 10.5.4 增大数据集 116 10.5.5 图形处理器与并行计算 117 10.6 全卷积神经网络与图像的分割 117 10.6.1 全卷积神经网络 117 10.6.2 图像分割 117 10.7 深度卷积神经网络在DNA序列分析中的应用 120 第11章 循环神经网络 124 11.1 循环的含义 124 11.2 循环神经网络的架构 125 11.3 循环神经网络中梯度的计算 128 11.4 长短期记忆网络 130 11.5 门控循环单元 133 11.6 循环神经网络的实现与应用案例 134 11.6.1 训练数据的获取 134 11.6.2 循环神经网络的训练 13511.6.3 报告对比 137 11.6.4 基于PyTorch的LSTM网络训练 138 第12章 生成对抗网络 140 12.1 引言 140 12.2 生成对抗网络原理 141 12.2.1 损失函数和极大极小博弈 142 12.2.2 算法 142 12.2.3 **判别器 143 12.3 GAN的缺陷：梯度的消失 144 12.4 深度卷积生成对抗网络的架构 145 第13章 有完整模型的强化学习 148 13.1 强化学习导引 148 13.2 马尔可夫奖赏过程 150 13.2.1 马尔可夫奖赏过程表现形式 150 13.2.2 状态值函数和贝尔曼方程 151 13.3 马尔可夫决策过程 151 13.3.1 值函数与贝尔曼方程 153 13.3.2 **策略和**值函数 156 13.3.3 行动值方法 159 13.4 动态规划 159 13.4.1 策略评价 160 13.4.2 策略改进 161 13.4.3 策略迭代 162 13.4.4 值迭代 162 13.4.5 异步动态规划 163 13.4.6 广义策略迭代 164 第14章 无完整模型的强化学习 166 14.1 蒙特卡罗方法 166 14.1.1 蒙特卡罗策略预测 167 14.1.2 行动值的蒙特卡罗估计 169 14.1.3 蒙特卡罗控制 170 14.1.4 无探索起始的既定策略蒙特卡罗控制 172 14.1.5 通过重要性抽样实现离策略预测 173 14.1.6 增量形式 175 14.1.7 离策略蒙特卡罗控制 176 14.1.8 蒙特卡罗方法与动态规划方法的比较 177 14.2 时间差分学习 178 14.2.1 时间差分预测 17914.2.2 Sarsa：既定策略时间差分控制 181 14.2.3 Q-学习：离策略时间差分控制 182 14.2.4 期望Sarsa 182 14.2.5 **偏差和加倍学习 183 14.2.6 持续探索 185 第15章 深度Q网络 186 15.1 深度Q网络原理 187 15.2 深度Q网络中的深度卷积神经网络 187 15.3 深度Q网络算法 188 15.4 深度Q网络训练 190 参考文献 194 附录A：AlexNet代码 196 附录B：Inception网络代码 198 附录C：ResNet代码 204 附录D：深度卷积神经网络的训练代码 208
